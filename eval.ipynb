{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import torch\n",
    "import unsloth\n",
    "import pandas as pd\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rizky\\Project\\cybersec-llm\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\rizky\\AppData\\Local\\Temp\\ipykernel_11164\\3850014559.py:3: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth.chat_templates import get_chat_template\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Mistral patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:33<00:00, 11.23s/it]\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 5020\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"preemware/Prox-MistralHermes-7B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prompt = \"\"\"You are a cybersecurity expert. Your task is to answer the following multiple-choice questions by providing only the letter of the correct option.\n",
    "\n",
    "## Input:\n",
    "{}\n",
    "\n",
    "## Output:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Question: What is the most effective technique for identifying the behavior of potential polymorphic malware during malware analysis?\n",
    "Options:\n",
    "\n",
    "A. Passing strings fetched at runtime through a disassembler\n",
    "B. Intercepting and modifying system calls with the ptrace system call\n",
    "C. Examining the import address table for unexpected changes\n",
    "D. Using sandboxing technologies to observe behavior\n",
    "\n",
    "Correct Option: [D]\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Using sandboxing technologies to observe behavior is the most effective technique for identifying the behavior of potential polymorphic malware. This approach allows analysts to see how malware operates in a controlled environment, making it possible to observe changes and behaviors without risking the integrity of the host system. Options such as 'Passing strings fetched at runtime through a disassembler' can be circumvented by malware that detects disassembler use. 'Intercepting and modifying system calls with the ptrace system call' might not reveal all behaviors, especially if the malware is aware and can disable or mislead ptrace. 'Examining the import address table for unexpected changes' is useful for static analysis but might miss runtime polymorphic behaviors where the malware modifies its code during execution.\n",
    "\n",
    "---\n",
    "\n",
    "Question: In the context of exploit development, what technique would most likely be used to carry out a privilege escalation attack on a modern Windows operating system?\n",
    "Options:\n",
    "A. Using a debugger to manipulate running processes and extract data\n",
    "B. Creating a custom encryption algorithm for secure communications\n",
    "C. Executing a buffer overflow attack to gain unauthorized access\n",
    "D. Employing social engineering tactics to gain initial network access\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A]\n",
      "\n",
      "Explanation:\n",
      "\n",
      "XOR encoding is a common technique used in exploit development to evade signature-based detection systems. It involves XOR-ing the payload with a key, which makes the payload appear random and unrecognizable to signature-based detection systems. The encoded payload still maintains its original functionality when decoded, ensuring the integrity of the exploit. Multiplying payload size would only increase the chances of triggering anomaly-based detection systems, encrypting packet headers is more relevant to network traffic analysis, and compressing the exploit code could potentially reduce its effectiveness due to the overhead of decompression.\n"
     ]
    }
   ],
   "source": [
    "# Improved prompt format - cleaner and more direct\n",
    "data_prompt = \"\"\"You are a cybersecurity expert. Answer the following multiple-choice question by providing the letter of the correct option with format [choice] and give explanation.\n",
    "Example:\n",
    "\n",
    "Question: What is the most effective technique for identifying the behavior of potential polymorphic malware during malware analysis?\n",
    "Options:\n",
    "[\n",
    "\"SQL Injection via email input\",\n",
    "\"Shell upload via form manipulation\",\n",
    "\"Cross-site Scripting (XSS) using URL parameters\",\n",
    "\"Denial of Service (DoS) through malformed packets\"\n",
    "]\n",
    "\n",
    "Correct Option: [D]\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Using sandboxing technologies to observe behavior is the most effective technique for identifying the behavior of potential polymorphic malware. This approach allows analysts to see how malware operates in a controlled environment, making it possible to observe changes and behaviors without risking the integrity of the host system. Options such as 'Passing strings fetched at runtime through a disassembler' can be circumvented by malware that detects disassembler use. 'Intercepting and modifying system calls with the ptrace system call' might not reveal all behaviors, especially if the malware is aware and can disable or mislead ptrace. 'Examining the import address table for unexpected changes' is useful for static analysis but might miss runtime polymorphic behaviors where the malware modifies its code during execution.\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "\n",
    "Options:\n",
    "{}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Test question - separate the question from examples\n",
    "test_question = \"In exploit development, what technique is commonly applied to evade basic signature-based detection systems while maintaining the integrity of the exploit payload?\"\n",
    "\n",
    "test_options = \"\"\"[\n",
    "\"XOR encoding in the payload\",\n",
    "\"Multiplying payload size\",\n",
    "\"Encrypting packet headers\",\n",
    "\"Compressing the exploit code\"\n",
    "]\"\"\"\n",
    "\n",
    "# Generate with more restrictive parameters\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer([\n",
    "    data_prompt.format(test_question, test_options)\n",
    "], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs, \n",
    "    max_new_tokens=1024,  # Much smaller - just need 1-2 tokens for the answer\n",
    "    temperature=0.3,   # Lower temperature for more deterministic output\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    repetition_penalty=1.1  # Prevent repetition\n",
    ")\n",
    "\n",
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "# Extract just the generated part\n",
    "generated_text = answer[len(tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)):]\n",
    "print(f\"{generated_text.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9879"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
